"0807.5065"	"one of the main goals of the search for periodic isolated sources of gravitational waves gw is to perform all sky surveys based on blind searches where the source parameters are unknown in this casehierarchical procedures are applied based on a sequence of increasing resolution steps in this paperwe study in details the problem of sensitivity loss due to discretization of parameters and to the needs to limit the computing cost with hough procedures in particular we propose and study the characteristics of a frequency hough procedure designed mainly to reduce the discretization problem and we compare it with the sky hough procedure which is actually used in the virgo collaboration the paper is organized as follows in sect 2 we present the basic scheme of the rome hierarchical procedure based on the main idea of coincidences among subsets of data in sect 3 we discuss the limits due to digitization of the sky hough procedure in sects 4 5 we present the new frequency hough procedure discussing details its implementation and its basic characteristics in sect 6 we present the study of amplitude losses due to digitization and thus efficiencies for both the procedures conclusions and comments are given in sect hierarchical procedures based on hough transform algorithms are applied by various groups in the gw community see for example references there are various ways of implementing the hierarchical procedure and the hough transform the hough transform is a linear transform that is used to recognize the parameters of the analytical description of a curve from the position of some points on it it operates on an image of points in our case the peakmap in the time frequency plane for each peak of this mapwe increase a set of bins of a multi dimensional histogram in our case a two dimensional histogram defined on the parameters space called the hough map in the old procedure the parameter space was the position of the source ie the celestial sphere and we fixed the spin down value for each hough map in the new one the parameter space is the plane 0 and for each hough map we fix the position of the source the mapping ie which points of the hough map must be increased for a certain point in the peakmap can be done in different ways we use always what we call the biunivocal mapping ie a mapping in which every point in the hough map derive from a single point of the peakmap at a given time it is easy to demonstrate that in this case the mapping is also uniform ie in the case of uniformly distributed random dots in the peakmap the expected value of the hough map 1 is a constant for all parameter value this value depending on the number n of the spectra of the peakmap and on the mapping defines the noise of the map it is binomially distributed with parameters n and 2 we will refer here to the rome scheme presently used in virgo data fig schema shows the basic scheme of the rome hierarchical procedure details on the main aspects of the procedure are given in references after data cleaning short time domain disturbances removal and short ffts data base sfdb creation peakmaps are computed using a very refined auto regressive algorithm to equalize the spectral data by an appropriate follow up of the noise peakmaps are frequency vs time maps obtained from equalized spectra by selecting all the local maxima above a chosen threshold an accurate cleaning of peakmaps by removing known noise lines and the more persistent lines is needed and its implementation is critical for the next step analysis on the cleaned peakmaps methods of peaks detection are applied that is transformation from the input plane to the hough plane thresholding and first order candidates selection candidate parameters are defined by source frequency celestial coordinates first spin down parameter the need for coincidences among candidates obtained in different subsets of data two in the scheme of fig fig schema has been discussed in references this method is very efficient to reduce the number of spurious candidates at a fixed threshold thus for a given false alarm probability we can lower the threshold with respect to the choice of not doing coincidences gaining in detection efficiency the method has a better efficiency when the data sets have similar sensitivities after the coincidence the survived candidates are analyzed coherently with longer ffts on corrected data then the spectral filtering is used to take into account the spread of the power in five bands as explained in reference finally second order candidates are produced as stated before the sky hough method shows amplitude losses and thus loss of sensitivity which are due to digitization of parameters this effect shows up mainly for the complexity of the transform together with the need of reducing the computing cost the method is based on a transform between the time frequency peakmap and the celestial sphere it is not simple for the non linearity of the mapping to reduce the computational effort we need to use look up tables which introduce further digitization errors to reduce the computational effort fast algorithms have been developed which require the use of a rectangular grid to map the sky compared to the optimal see later grid the rectangular one has over resolution in some regions of the sky this leads also to a higher number of candidates the use of the celestial map as the space to spot the candidates is very prone to artifacts see some regions are always privileged that is they have a higher candidates number with respect to the expectation the problem arises because each hough map is constructed over the whole sky hence it seemed important the study of alternative procedures given the observation that most of the problems are related to the complexity of the transformation we exploit the possibility of the use of a different but simpler transformation a part the simplicity of the transformation we obviously need to study a procedure which is less or equivalently computationally expensive therefore we studied a procedure which has a better or equivalent sensitivity at the same computational cost of the sky hough the transformation we propose transforms the time observed frequency plane into the source frequency spin down plane lets go into details if 3 is the frequency doppler corrected for a given sky direction 4 the source intrinsic frequency 5 the first spin down parameter 6 the time at the detector and 7 a reference time we have that 8 a straight line in the hough plane we then get the following 9 each point in the input plane 10 that is a peak in the doppler shifted peakmap is transformed into a straight line in the hough 11 plane with slope 12 the slope depends on the choice of the reference time if we choose 7 equal to the beginning time of the data we analyze then the slope is always negative and inversely proportional to the time gap this is the choice we have done here in addition considering the width 13 of the frequency bins in the input plane we notice that each peak is transformed into a stripe among two parallel straight lines 14 it is a linear transformation now the input plane is obtained from the original peakmap by correcting it for the doppler shift due to the earth revolution and rotation for each point in the sky grid we need to analyze thus time is the time at the detector and frequency the observed frequency after the doppler correction but as each sfdb is short enough to not be affected by a time varying doppler shift then the doppler effect removal from the original peakmap obtained from the collection of all the sfdb data reduces to a very simple shifting procedure of the peakmap bins in the analysis scheme this bins shift is part of the hough procedure in the following we give details on the construction of the map the frequency hough map is constructed using the direct differential method as is done with the sky hough with this method instead of building directly the hough map one builds a map that if integrated ie summed over bins from left to right gives the hough map this is important to minimize the number of floating point operations as already explained for each sky position the input peakmap is got from the original one by shifting bins to correct for the doppler effect the sky is sampled with a non uniform covering grid which will be later discussed herewe explain in detail the technique by giving the sequence of operations for each point in the sky grid for each coordinate in the input plane 10 and for each spin down value 15 the map is incremented by 1 in the point 16 and decremented by 1 in the point 17 hence for each sky position a differential map is constructed the sum of the bins along the frequency direction is then performed to construct the final integral map this two dimensional histogram is the frequency hough map in the algorithm implementationwe plan to divide the input peakmap into 10 hz bands thus constructing for each position in the sky a different hough map every 10 hz in case there is the need to exploit higher order one spin down parameters one or more loops has have to be added to the sequence of operations to scan the discrete set of values of the new parameters this clearly influences the computing cost but does not change the basics of the method let s first discuss two peculiar aspects of this new method which are the basis of its appeal from the given analysis scheme it is easy to see that the frequency resolution for the estimation of the source frequency 4 can be enhanced with respect to the binning frequency 13 without relevantly affecting the computational effort in fact the use of a resolution 18 with 19 affects only the size of the hough map this has a computational cost only when summing over the bins to construct the integral map from the differential one but we notice that the total cost of the construction of the hough map is due to the construction of the differential map dominated by the number of peaks in the peakmap and to the construction of the integral map dominated by the number of bins the former in all practical cases is the one which dominates the possibility to enhance the frequency resolution results to be as will be shown in the next sections a very important peculiarity of the new method it which enhances considerably the efficiency by reducing the digitalization effect the same in the sky hough procedure would have a relevant computational cost regarding the increasing of the spin down resolution it would cost for both the procedures the better the resolution in the spin down estimation the higher is the number of loops of the procedures herewe describe how we construct the grid on the sky suppose two sources at the same frequency 4 and same latitude 20 their angular delay 21 with respect to the detector rotation produces a time delay 22 the two sources will then have the same frequency variation at the detector which is the classical equation due to the doppler effect 23 but with time delay 24 the observed frequency difference has thus a maximum value which is given by 25 thus the angular resolution is in radians 26 where 27 is the number of points in the doppler band for a signal of max frequency 4 28 and 29 we now repeat the same reasoning supposing the two sources at the same frequency 4 and same longitude 30 the two sources will have the same frequency variation at the detector now given by 31 but with an angular delay 32 the observed frequency difference has a maximum value which is 33 we obtain for the angular resolution in radians 34 using eqs gammalong and gammalat we get 35 36 using these equations we construct the grid on the sky which we call the optimal grid the points of the grid are not uniformly distributed with a simulation we have estimated the the number of points in the grid 37 which is in the high frequency limit 38 39 is an extra resolution factor which can be greater than 1 to enhance the efficiency but even less than 1 to save computing cost obviously worsening the efficiency figfig gridsim1 shows the optimal sky grid for 40 which corresponds to a source frequency 41 hz as already said the grid used in the sky hough method is not optimal but rectangular to use fastest computing algorithms the number of points in this rectangular grid is 42 which is asymptotically a factor 43 higher then the number of points of the optimal grid in factthis grid has to be over resolved to maintain the same sensitivity of the corresponding optimal grid further we note that this over resolution produces a higher number of candidates from certain sky positions x axis ecliptical longitude degrees from 0 to 400 y axis ecliptical latitude degrees from 100 to 100 the number of points in the map is 372902width453 the sensitivity of the sky hough procedure is affected by artifacts ie an excess of candidates in some places of the sky map which are due to local spectral disturbances the effect ca nt be eliminated because each map is constructed over the whole sky and hence the threshold for candidate selection has to be the same for the whole sky using the frequency hough procedurethis effect disappears because each map is constructed for only one position in the sky so because of the adaptivity of the threshold if a sky region gives an excess of candidates the threshold is raised and then there is a loss in sensitivity only for that sky region we are now ready to enter into details by studying the efficiency of both the methods by the use of simulations figure fig gridsim2 is an example of how a frequency hough map looks like having injected into white noise three signals at different frequencies and spin down to study the efficiency of the methods as a function of the frequency over resolution factor we have simulated a signal in the absence of noise the reason for this is that we were interested in studying only the losses due to the discretization errors the parameters chosen for the simulation are similar to actual situations detector parameters source expected parameters the parameters of the simulation are shown in table tab par fig freqloss shows the amplitude loss versus the frequency over resolution factor 45 the loss was calculated as the average value of all the peaks found in the 500 spectra it is important to remember that our procedure considers peaks only the maxima above threshold the result is clear using 46 the amplitude loss is 36 47 the efficiency 48 while with 49 which is the only practically possible choice of the sky hough the amplitude loss is 116 47 the efficiency 50 from the figure we notice that there is no further gain of increasing the over resolution factor over 10 thus we fixed to 10 the over resolution factor for the frequency hough in next simulations results with 46 are thus for the frequency hough results with 49 are for the sky hough once we have fixed the frequency over resolution factor we wanted to quantify how the increasing of the spin down resolution from the nominal one would affect the sensitivity the results are in fig fig freqloss1 which shows the loss in amplitude vs the spin down over resolution factor for both the cases 49 sky hough and 46frequency hough it can be noticed that in the case of the frequency hough even for the worst analyzed situation which corresponds to the nominal spin down step 51 the loss is quite small is is 36 47 the efficiency 48 the situation is worst for the sky hough where the loss in amplitude at the nominal spin down step is 116 47 the efficiency 50 the improvement obtained by a better spin down resolution is not so important as can be seen from the figure it seems reasonable given the observation that increasing the spin down resolution has a computational cost for both the methods to use the nominal 52 resolution x axis equal to 1 in the figure to study the loss due to the sky grid resolution we have simulated 50 signals randomly distributed over the sky we have then looked for results using the optimal grid again registering the average value of all the detected peaks in what follows we suppose to use the optimal grid for both the procedures sky and frequency hough figfig loss_spinres shows the amplitude losses as a function of the over resolution sky map factor 39 in the two cases of 46 left frequency hough and 49 right sky hough the amplitude loss for 44 is 53 for the frequency hough and 54 for the sky hough again a better efficiency for the new procedure we notice that the use of an over resolution for the sky map would have an impact on the computing cost with both the procedures the figures compare the loss when 46 left frequency hough and when 55 right sky houghtitlefigwidth302 the figures compare the loss when 46 left frequency hough and when 55 right sky houghtitlefigwidth302 we see that the ratio of the amplitude efficiencies is 57 which in power is 1317 from this we can compute the gain in computing cost for the same sensitivity let us firstly recall that the 58 sensitivity in the hierarchical search is proportional to 59 and the computing cost to 60 thus the equivalent fft length factor is 611734 and the gain in computing cost is 6252 that is the ratio of computing costs needed to have the same 58 sensitivity the adaptivity that is the weight of peaks to consider the noise level and the gain due to the antenna pattern toward a direction is with this approach immediate and very simple as each hough map is done for a single sky position it has been shown with the sky hough that the adaptivity of the procedure is a very important task for the analysis this new procedure is appropriate also for all those situations in which the source position is known and we should estimate only source frequency and spin down with a proper choice of parameters it is also possible to detect and hence remove spurious signals with a constant or linearly varying frequency on the latter point we are now working to study the efficiency of this method in terms of rejection of spurious lines in the peakmap we know that this is a very critical task for the analysis since the presence of spurious lines highly affects the sensitivity of the search we expect this new method to be much more insensitive to the presence of spurious lines since in the chosen hough plane spurious lines and gw signals should have a very different and well separable behavior b krisnan a sintes m a papa b f schutz s frasca c palomba _physrevd70082001_ 2004 the hough transform search for continuous gravitational waves a sintes b krisnan _physconfser32206211_ 2006 improved hough search for gravitational wave pulsars p astone s frasca c palomba_cqg 22s1197s1210_2005 the short fft database and the peakmap for the hierarchical search of periodic sources s frasca p astone c palomba_cqg 22s1013s1019 _ 2005 evaluation of sensitivity and computing power for the virgo hierarchical search for periodic sources c palomba p astone s frasca _cqg 22s1255s1264_2005 adaptive hough transform for the search of periodic sources f acernese et al virgo coll _ cqg 24s491s499 _ 2007 coincidence analysis between periodic source candidates in c6 and c7 virgo data f acernese et al virgo coll _ proceedings of the eleventh marcel grossmann meeting on general relativity berlin 2006 edited by h kleinert rt jantzen and r ruffini world scientific singapore _ 2008 first coincidence search among periodic gravitational wave source candidates using virgo data p astone s frasca c palomba_proceedings of the eleventh marcel grossmann meeting on general relativity berlin 2006 edited by h kleinert rt jantzen and r ruffini world scientific singapore _ 2008 incoherent strategies for the network detection of periodic gravitational waves c palomba s frasca _cqg 21s1645s1654 _ 2004 spectral filtering for hierarchical search of periodic sources "
"1512.09024"	"recently it was discovered that feynman integrals obey functional equations different examples of functional equations were presented in refs in these articlesonly one loop integrals were considered in the present paperwe propose essentially new methods for deriving functional equations these methods are based on algebraic relations between propagators and they are suitable for deriving functional equations for multi loop integrals also these methods can be used to derive functional equations for integrals with some propagators raised to non integer powers our paper is organized as follows in sec 2 the method proposed in ref is shortly reviewed in sec 3 a method for finding algebraic relations between products of propagators is formulated we describe in detail derivation of explicit relations for products of two three and four propagators also algebraic relation for products of arbitrary number of proparators is given these relations are used in sec4 to obtain functional equations for some one as well as two loop integrals in particular functional equation for the massless one loop vertex type integral is presented also functional equation for the two loop vertex type integral with arbitrary massesis given in sec another method for obtaining functional equations is proposed the method is based on finding algebraic relations for deformed propagators and further conversion of integrals with deformed propagators to usual feynman integrals by imposing conditions on deformation parameters to perform such a conversion the 0 parametric representation for both types of integralsis exploited the method was used to derive functional equation for the two loop vacuum type integral with arbitrary masses as a by product from this functional equation we obtained new hypergeometric representation for the one loop massless vertex integral in conclusionwe formulate our vision of the future applications and developments of the proposed methods the method for deriving functional equations proposed in ref is based on the use different kind of recurrence relations in particular in refs generalized recurrence relations were utilized to obtain functional equations for one loop feynman integrals in general such recurrence relationsconnect a combination of some number of integrals 1 corresponding to diagrams say with 2 lines and integrals corresponding to diagrams with fewer number of lines diagrams with fewer number of lines can be obtained by contracting some lines in integrals with 2 lines integrals corresponding to such diagrams depend on fewer number of kinematical variables and masses compared to integrals with 2 lines such recurrence relations can be written in the following form 3 where 4 and 5 are ratios of polynomials depending on masses 6 scalar products 7 of external momenta powers of propagators 8 and parameter of the space time dimension 9 at the left hand side of eq nconnectr we combined integrals with 2 lines and on the right hand side integrals with fewer number of lines in accordance with the method of ref to obtain functional equation from eq nconnectr one should eliminate terms on the left hand side by defining some kinematical variables from the set of equations 10 if there is a nontrivial solution of this system and for this solution some 11 are different from zero then the right hand side of eq nconnectr will represent functional equation for the one loop integrals with 2 propagators 12 where 13 different types of recurrence relations were given in refs diagram corresponding to this integral is given in figure 1 external legs in refs the following relation was derived 14 where the operators 15 shift index of propagators by one unit 16 1718 19 here 20 are external momenta going through lines 21 respectively and 22 is mass attributed to 23th line gram determinant 24 and modified cayley determinant 25 are polynomials depending on scalar products and masses it is assumed that these scalar products are made of 9 dimensional vectors and 24 and 25 are not subject to any restriction or condition specific to some integer values of 9 reducedtod is written in the form corresponding to eq nconnectr to eliminate integrals with 2 lines on the left hand side of eq reducedtod the following conditions to be hold 26 eq reducedtod is valid for arbitrary kinematical variables and masses solution of eqs sharik can be easily done with respect to two kinematical variables or masses starting from 27 substitution of such solutions into eq reducedtod gives nontrivial functional equations the method for obtaining functional equations by eliminating complicated integrals from recurrence relations is quite general one however for multi loop integrals depending on several kinematical variables derivation of equations like eq reducedtod is computationally challenging in the next sections we will describe easier and more powerful methods that can be used for deriving functional equations for multi loop integrals setting 28 in eq reducedtod and imposing conditions sharik leads to the following equation 29 in eq fe_n_points integrands of 30 are products of 31 propagators depending on different external momenta ie each term in this relation corresponds to the same function but with different arguments in fact functional equations considered in refs are of the same form as eq fe_n_points the question naturally arises this relationship holds for integrals or it can be obtained as the consequence of a relationship between integrands by inspecting eq fe_n_points one can suggest the following form of the relation between products of propagators of integrands 32 where 33 in what follows we will omit 34 term assuming that all masses have such a correction additionally we assume that vectors 35 are linearly dependent ie the gram determinant for the set of vectors 36 is equal to zero such a condition is valid for all examples considered in refs now let s consider in detail implementation of our prescription for products of 23 and 4 propagators at 37 relation usual_props reads 38 where 39 according to our assumption three vectors 404142 are linearly dependent without loss of generality we may assume that 43 furthermore we assume that 44 will be integration momentum and scalar quantities 4546 47 47 do not depend on 44 putting all terms in eq 2prop_relation over a common denominator and then equating to zero the coefficients in front of various products of 48 4950 yields the following system of equations 51 solution of this system of equations is 52 where 53 is a root of the equation 54 with 55 this solution can be rewritten in an explicit form 56 where 57 now let s find algebraic relation for the products of three propagators at 27 eq usual_props reads 58 where 59 60 61 are defined in eqp1p2p3 and 62 in complete analogy with the previous case we can represent one momentum as a combination of other ones without loss of generality we may write 63 where 64 for the time being are arbitrary coefficients putting all terms in eq 3prop_relation over a common denominator and then equating to zero the coefficients in front of various products of 65 66 67 68 yields the following system of equations 69 solving these equations for 45 46 70 71 72 we have 73 where 74 is solution of the equation 75 here 76 let us now turn to the derivation of algebraic relation for the product of four propagators at 77 usual_props reads 78 where 59 60 6179 are defined in eqs p1p2p3 d4 80 and 81 is a linear combination of vectors 40 82 83 putting all terms in eq 4prop_relation over a common denominator and then equating to zero the coefficients in front of different products of 48 84 yields system of equations 85 solving this system for 45 46 7086 87 88 we have 89 where 90 is a solution of the equation 91 with 92 eqs 3prop_relation 3prop_relation and 4prop_relation will be used in the next sections to derive functional equations for the propagator vertex and box type of integrals relations between products of five and more propagators can be easily derived in the same way as as it was done for products of two three and four propagators from eq usual_props one can derive system of equations and find its solution for arbitrary 2 multiplying both sides of eq usual_props by the product of 93 propagators 94 yields 95 or 96 since we assume linear dependence of vectors 97 without loss of generality we may write 98 substituting pnp1 into eqini_equ collecting terms in front of 48 84 and terms without 44 equating them to zero after some simplifications yields the following system of 99 equations 100 solving eq sumy for one of the 64 an substituting this solution into eq kwadraticy gives quadratic equation for the remaining 64 this quadratic equation can be solved with respect to one of the parameters 64 thus the solution of the system of equations xequs sumy kwadraticy will depend on 101 arbitrary parameters 64 and one arbitrary mass 102 it is interesting to note that for any 2 functional equations for integrals with all masses equal to zero and functional equations for integrals with all masses equal are the same in case of equal masses two mass dependent terms in eq kwadraticy cancel each other due to eq sumy in both cases systems of equations for 103 104 are the same and therefore arguments of integrals are the same 2prop_relation is analogous to the equation for splitting propagators presented in ref 3prop_relation is a generalization of eq 2prop_relation indeed setting 105 canceling common factor 61 on both sides of eq 3prop_relation yields relation similar to 2prop_relation in turn 4prop_relation is a generalization of 3prop_relation multiplying algebraic relations 2prop_relation3prop_relation 4prop_relation by products of any number of propagators raised to arbitrary powers 106 107_j and integrating with respect to 44 we get a functional equation for one loop integrals 2prop_relation 3prop_relation 4prop_relation also can be used to derive functional equations for integrals with any number of loops multiplying algebraic relations for propagators by function corresponding to feynman integral depending on momentum 44 and any number of external momenta and then integrating with respect to 44 will produce functional equations just for demonstrational purposes we present graphically in figure 2 functional equation based on 2 propagator relation propagator functional equation the blob on this picture correspond to either product of propagators raised to arbitrary powers or to an integral with any number of loops and external legs one of the external momenta of this multi loop integral should be 44 in this section several particular examples of functional equations resulting from algebraic relations for products of propagators will be considered first we consider the simplest case namely functional equation for the integral 108 109 k_1p_k2m_k2 integrating both sides of eq 2prop_relation with respect to 44 we get 110 the arguments 111 112 of integrals on the right hand side depend on 113 47 114 substituting solution for 64 from eq y_for_2prop into eq p13_p23 yields 115 in this equation 116 is an arbitrary parameter and can be taken at will functional equation prop_fe is in agreement with the result presented in refs functional equations for the vertex type integral 117 k_1p_22m_2 2 k_1p_32m_3 2 i3definition aligned can be obtained from eq 2prop_relation as well as from eq 3prop_relation multiplying eq 2prop_relation with the factor 118 where 119 and integrating over 44 leads to the equation 120 this equation in terms of integrals 121 reads 122 two more functional equations can be obtained from eq fe_for_vertex by symmetric permutations 123 and 124 another functional equation for the vertex type integral can be obtained by integrating eq 3prop_relation with respect to 44 125 where 126 there is an essential difference between functional equation eq fei3massiv obtained from eq 2prop_relation and functional equation fei3massive derived from eq 3prop_relation for example at 127 eq fei3massiv becomes trivial while from eq fei3massive for the integral 128 we obtain nontrivial functional equation 129 where 74 is a root of the quadratic equation 130 if one argument of 131 is zero then by applying functional equation fe_triangle such an integral can be expressed in terms of integrals 121 with two arguments equal to zero for example at 132 and 133 the relation fe_triangle becomes 134 this is a typical example how functional equations can be used to simplify evaluation of an integral by reducing it to a combination of integrals with fewer number of arguments at 135 similar to the previous case eqfei3massiv degenerate while from eqfei3massive for the integral 136 we obtain nontrivial functional equation 137 where 74 is a root of the quadratic equation 138 eqs fe_triangle_eqm l3_eqm are identical to eqs fe_trianglelambda3_zero_masses respectively and therefore functional equation for the integral with massless propagators and functional equation for the integral with all masses equal are the same fe_triangle_eqm at 132 and 133 leads to the relation similar to 1zero_2zeros 139 this is not surprising because coefficients of the eq fe_triangle_eqm are mass independent and in the integrand 140 and 34 appear in the covariant combination 141 for this reason the similarity of functional equations for massless integrals and integrals with all masses equal take place for integrals with more external legs and more loops functional equations for the box type integrals can be obtained by multiplying relation 2prop_relation by two propagators or by multiplying relation 3prop_relation by one propagator and then integrating over momentum 44 yetanother relation can be obtained just by integrating eq 4prop_relation over momentum 44 142 here 90 is defined in eq lambda4 and 143144 145 are arbitrary parameters and 146 arbitrary parameters in this functional equation can be chosen from the requirement of simplicity of evaluation of integrals on the right hand side of eq box_func_equ or from some other requirements for example one can choose these parameters by transforming arguments to a certain kinematical region needed for analytic continuation of the original integral the method described in the previous section can be applied to multi loop integrals consider for example integral corresponding to the diagram given in figure 3 if we multiply eq 2prop_relation by the one loop integral depending on 44 147 k_1k_22m_5 2 and integrate with respect to momentum 44then we obtain functional equation 148 where 149k_2q_22m_2 2 k_1 2m_3 2k_1k_22m_4 2 rdefinitionaligned 150 integrals of this type arise for example in calculations of two loop radiative corrections in the electroweak theory instead of the integral 151 one can consider derivative of 152 with respect to 116 which is uv finite 153k_2q_22m_2 2 k_1 2m_3 22k_1k_22m_4 2 r3definitionaligned integral 154 satisfy the following functional equations 155 this relation can be used for computing basis integral arising in calculation of two loop radiative correction to the ortho positronium lifetime in particular one of these basis integrals corresponds to kinematics 135 156 157 in this case relation fe3 reads 158 integral on the right hand side is in fact propagator type integral with one massless line applying recurrence relations given in ref this integral can be reduced to simpler integral 159 2k_1q_12m2 23d3 j_111d2m2aligned where 160 k_2q2m2 at 161 the result for 162 is known 163 d3_3f_2arrayc14d2d122array1aligned and it can be used for the 164 expansion of 152 and 154 as was already mentioned at 156 157 integrals on the right hand side of eqfe_for_r correspond to propagator type integrals analytic result for 152 reads 165aligned where 166 we checked that several first terms in the 167 expansion of 152 and 154 are in agreement with results of the main profit from functional equations for 152 and 154 comes from the fact that vertex integrals were expressed in terms of simpler propagator type integrals the method described in the previous section does not work for deriving functional equations for all kinds of feynman integrals for example we did not found functional equation for the two loop vacuum type integral given in figure 4 in this sectionwe shall describe another method that extends the class of integrals for which we can obtain functional equations the method is based on transformation of functional equations for some auxiliary integrals depending on arbitrary parameters into functional equations for integrals of interest such functional equations will be derived from algebraic relations for deformed propagators which will be defined in the next section these auxiliary integrals will be transformed into 0 parametric representation in general characteristic polynomials of these integrals in 0 parametric representationdiffer from those for the investigated integral functional equation for the integral of interestcan be obtained in case when it will be possible to map characteristic polynomials of auxiliary integrals with deformed propagators to characteristic polynomials of this integral such a mapping will be performed by rescaling 0 parameters and appropriate choice of arbitrary deforming parameters in the previous section to derive functional equation we added to our consideration a propagator with combination of external momenta taken with arbitrary scalar coefficient now we consider generalization of this method to find functional equation for 168loop feynman integral depending on 169 external momenta we start from the relation of the form 170 where 171 is defined as 172 with 173 and 174 175 for the time being are arbitrary scalar parameters some of these parameters as well as 176 will be fixed from the equation x_parameters another part of these parameters will be fixed from the requirement that the product of propagators in x_parameters should correspond to the integrand of the integral with the considered topology we would like to remark that instead of deformation of propagators proposed in eqs deformed_propdeformed_momentum one can use other deformations for example all terms in denominators of propagators can be taken with arbitrary scalar coefficients 177 to establish algebraic relation x_parameters we put all terms over a common denominator and then equate coefficients in front scalar products depending on integration momenta solving obtained system of equations gives some restrictions on the scalar parameters in general integrals obtained by integrating products of deformed propagators will not correspond to usual feynman integrals further restrictions on parameters should be imposed in order to obtain relations between integrals corresponding to feynman integrals coming from a realistic quantum field theory models as an example let us consider derivation of functional equation for the two loop vacuum type integral given in figure 4 178 analytic expression for this integral was presented in ref instead of this integralwe will first consider an auxiliary integral with integrand made from deformed propagators defined in eqsdeformed_prop deformed_momentum 179 where 180 for the product of three deformed propagators one can try to find an algebraic relation of the form 181 where 182 183184 are defined in eqd123_for2loop_bubble and 185 here 186 are arbitrary masses 187 188 189 190 191 are undetermined parameters and 44 192 will be integration momenta we would like to notice that eq equ_with_redefined_masses2 is valid for integrals but not for their integrands this is due to the fact that the factor in front of integral that comes from the scaling of 0 parameters in parametric integral is not fully compensated by scaling momenta given in eq scaling_momenta at 246the dependence on all parameters 247248249 in eqs equ_with_redefined_masses_mm4nz equ_with_redefined_masses2 drops out and the integral 250 reduces to a comination of simpler integrals 251 analytic expression for the integral 201 with one mass equal to zero is known under assumption that 252 it reads 253 j0_hgf from functional equation j0_mm4_zero as a by productone can get a new hypergeometric representation for the one loop massless vertex type integral in ref an interesting relation between the dimensionally regularized one loop vertex type integral 254 and the two dimensional integral 255 was discovered 256 functional equation j0_mm4_zero with 257 defined in eq j0_hgf provide us a new hypergeometric representation for the integral 121 with massless propagators formula for the one loop massless vertex integral in terms of other gauss hypergeometric functions is given in ref finally we summarize what we have accomplished in this paper first of all we formulated new methods for deriving functional equations for feynman integrals these methods are rather simple and do not use any kind of integration by parts techniques second it was shown that integrals with many kinematic arguments can be reduced to a combination of simpler integrals with fewer arguments in our future publicationswe are going to demonstrate that in some cases applying functional equations one can reduce the so called master integrals to a combination of simpler integrals from what we would like to call a universal basis of integrals the method based on algebraic relations for deformed propagators can be used not only for vacuum type of integrals but also for integrals depending on external momenta in the present paper we considered rather particular cases of functional equations the systematic investigation and classification of the proposed functional equations requires application of the methods of algebraic geometry and group theory at the present momentit is not quite clear whether functional equations derivable from recurrence relations can be reproduced by the methods of algebraic relations between products of propagators described in section 3 and section 5 a detailed consideration of our functional equations and their application to the one loop integrals with four five and six external legs as well as to some two and three loop feynman integrals will be presented in future publications this work was supported by the german science foundation dfg within the collaborative research center 676 _ particle strings and the early universe the structure of matter and space time_ i am thankful to ol veretin for providing results for integrals contributing to ortho positronium lifetime described in ref "
"0908.1812"	"this review focuses specifically on what we have learned about the progenitors of core collapse supernovae cc sne by examining images of the supernova sn sites taken prior to the explosion by registering pre sn and post sn images usually taken at high resolution using either space based optical detectors or ground based infrared detectors equipped with laser guide star adaptive optics systems lgs ao about one dozen cc sn progenitors have now been directly detected ie shown to be spatially coincident with the sn in pre sn images with roughly two dozen upper limits derived from non detections this field has come a long way in the last decade and promises to advance rapidly as more and more nearby galaxies hosts of future cc sne have high resolution images added to the archive this review is organized as follows following a brief summary of sn classification and stellar evolution theory 2 one example from each of the following three categories of progenitor studiesis provided 3 ordered from most to least common 1 no progenitor star detected in pre sn images 2 likely progenitor star identified via spatial coincidence in pre sn and post sn images 3 progenitor star detected in pre sn images and subsequently confirmed by demonstrating its absence in images taken after the sn has faded beyond detection a summary of overall results to date for each sn typeis then given 4 followed by a brief discussion of outstanding questions and areas in which future progress is likely 5 note that discussion is limited to what the examination of images of sn sites taken prior to the explosion has taught us and necessarily excludes or relegates to very brief comment such related investigations as sn environments eg see also the article by elias rosa in this volume and sn progenitor forensics eg see also the article by modjaz in this volume for a comprehensive discussion of all such related areas see the recent review by it is typical to subdivide cc sne into at least five major categories see for a thorough review ii plateau ii p hydrogen in spectrum and plateau in optical light curve ii linear ii l hydrogen in spectrum no plateau in optical light curve iin hydrogen in spectrum and spectral and photometric evidence for interaction between sn ejecta and a dense circumstellar medium csm iib hydrogen in spectrum initially but transforms into a hydrogen deficient spectrum at later times and ib c no evidence for hydrogen in spectrum at any time where the ordering is a roughly increasing one in terms of inferred degree of envelope stripping prior to explosion ie ii p are the least stripped at the time of explosion and ib c are the most stripped while most of this review focuses on the observational advances that have been made theoretical input is critical to translate observed progenitor luminosity or limits into zero age main sequence masses 0 and stellar evolutionary states among the most complete and accessiblestars stellar evolution models at present are the metallicity dependent models produced with the cambridge stellar evolution code stars the descendant of the code developed originally by and updated most recently by 2004 see also and references therein since they follow stellar evolution up to the initiation of core neon burning which is likely to give an accurate indication of the pre sn luminosity the hertzsprung russell diagram hrd of the stars evolutionary tracks are shown in figure 1 for stars ranging in initial mass from 1 comparison with other contemporary model grids eg show that the endpoints for stars in the 2 range differ by at most 3 dex in luminosity among the codes which gives some assurance that systematic uncertainties are not great at least at the low mass end for red supergiant rsg stars two areas of uncertainty in need of better quantification or at least agreement within the community include the effects that stellar rotation and mass loss might have on the observable characteristics of stars prior to core collapse not surprisingly when no progenitor star is actually detected at the sn location in pre sn images only an upper limit to the progenitor s luminosity and hence mass can be derived to illustrate the analysis process in such a situation i consider sn 2006my an snii p that exploded in a galaxy 4 mpc away nearly all sne with progenitor studies are within 5 mpc since source confusion becomes an increasing problem with distance details for this particular event are provided by here i briefly outline the steps my colleagues and i took to derive an upper mass limit on its progenitor the _ hubble space telescope _ _ hst _ imaged the site of sn 2006my using the wide field and planetary camera 2 wfpc2 in 1994 pre sn and again in 2007 shortly after explosion we registered the two images and pinpointed the sn location to better than 30 milli arcsec in the pre sn frame figure 2a b such fine registration allowed us to rule out a nearby point source source 1 in figure 2a as the progenitor star with greater than 6 confidence note that this source had been previously identified by as the likely progenitor based on registration with lower resolution ground based optical post sn images we next set an 7band detection limit in the pre sn frame by placing artificial stars of progressively fainter magnitude at the sn location and letting the photometry software in this case hstphot see attempt to detect them the point at which the software no longer detected a point source then serves as the limiting upper magnitude for the progenitor star to translate this single filter detection limit into a luminosity we assumed that the progenitor was a rsg given other sn ii p progenitor detections this seems a reasonable assumption see 32 and 4 and then determined the greatest bolometric magnitude it could have had while still remaining below our detection threshold this is accomplished through 8 where 9 is the distance modulus of the host galaxy ngc 4651 10 the extinction to sn 2006my 7 the 7band detection threshold 11 the color range of rsg stars ie spectral types 12 and 13 the bolometric correction corresponding to each 14 upon adopting the most conservative values for each of the parameters ie the ones that produce the least restrictive 15 for the progenitor s upper luminosity limit and allowing for a maximum systematic uncertainty of 02 dex in the theoretical stellar model endpoints see 2 the limiting bolometric magnitude above which any rsg would have been detected in our pre sn image 15 is derived we then compared this with the final luminosity of stars with 16 predicted by the stars stellar evolution models figure 2c to derive an upper bound on the progenitor mass of 17 from this analysis then we conclude that any rsg progenitor with an initial mass greater than 18 would have been detected using our analysis procedure analyses similar to that described here for sn 2006my have been carried out on each of 22 non detections in pre sn images as we shall see 4 it is the sheer number of such progenitor non detections that permits rather strong conclusions to be drawn about cc sn progenitors from this category of progenitor studies next we consider the individually more revealing situation where an object coincident with the transformed sn location is actually detected in the pre sn images a situation that exists now for 11 cc sne as an outstanding example of the analytic power provided by having multi filter pre sn images available especially in the near infrared for rsg progenitors we consider the recent work of on sn 2008bk a very nearby 19 mpc sn ii p in this case pre sn ground based images in 20 were registered with post sn lgs ao 21band images to yield solid progenitor star detections in 22 and upper luminosity limits in 23 and 24 when compared with the known spectral energy distribution sed of rsg a good match for the progenitor of sn 2008bkis found with a progenitor of spectral type m4i figure 3 from comparison with the stars stellar evolutionary models an initial progenitor mass of 25is derived for this sn similar studies on seven other detected sn ii p progenitors have found stars consistent with rsg in all cases providing nice agreement between theory and observation as we shall see in 4 however the _ range _ of masses inferred for these rsg progenitors is somewhat unexpected finally we consider the most satisfying situation where images taken before during and long after the sn explosion exist that clearly show the progenitor star the sn and the absence of the progenitor star respectively such a sequence provides nearly conclusive proof of the progenitor star s identity currently such a time series exists for only two objects sn 1987a eg and sn 2005gl because the case of sn 1987a is well known i present sn 2005gl as the example of this situation it also clearly demonstrates the investigative power provided by having a third observation long after the sn has dropped below detection as shown by early spectra of sn 2005gl exhibited the classic features of a type iin event showing narrow but resolved lines of hydrogen superposed on an intermediate width component on an otherwise featureless continuum analysis of the spectral features indicate ejecta interacting with a dense csm whose properties suggest that the progenitor star exploded shortly after an lbv like mass loss episode comparison of a pre sn _ hst _ image with a post sn image obtained from the ground using the lgs ao at the keck ii telescope established a spatial coincidence between the sn and a very bright source possessing an estimated luminosity of over 26 see figures 4a and 4b the only single stars known to possess such an extraordinary luminosity are very massive 27 see figure 1 which conventional theory predicts should explode only after the lbv phase has ended initially strong claims for the unexpectedly luminous progenitor sn 2005gl association had to be tempered by consideration of the distance of sn 2005gl s host galaxy at over 60 mpc away the 28 resolution of the pre sn _ hst _ image corresponds to 5 pc which raises suspicion that the object could be eg an unresolved stellar cluster or association of several massive stars with only part of the light coming from the actual progenitor of sn 2005gl additional observations therefore were clearly needed to settle the case and two years later an additional _ hst _ observation was made this observation demonstrates that the luminous source in the pre sn image has indeed disappeared figure 4c which implies that the progenitor of sn 2005gl was a single extremely luminous star that exploded while in the lbv phase such a luminosity is indicative of having had an initial mass of 29 which likely left behind a stellar mass black hole eg in addition to exploding during an unexpected evolutionary phase the very fact _ that _ such a massive star is demonstrated to have exploded at all as opposed to directly collapsing to a black hole with no sn explosion is important since the optical signature produced at the time of stellar collapse to a black hole is at present virtually unconstrained by either observation or theory see eg and references therein the three examples discussed in 3 serve to illustrate how the science of seeking progenitors in pre sn images is carried out and what conclusions can typically be drawn i now briefly summarize results to date arising from direct progenitor searches in pre sn images for a more comprehensive review see type ii plateau sne ii p are by far the most well defined category of cc sne in terms of direct observational progenitor constraints having had eight putative progenitor detections made and 12 upper luminosity limits established all of the available evidence suggests that rsg are the immediate progenitors of sne ii p by employing a uniform reduction and analysis procedure has produced the cumulative frequency distribution shown in figure 5 for sne ii p from which an intriguing result is immediately evident all but one of the sne ii p have initial masses constrained to be 30 with the most massive _ detected _ progenitor of an sn ii p having a mass of only 31 this is surprising since rsg up to 32 are clearly observed in the local group and references therein and would have easily been detected in the pre sn images this lack of massive rsg progenitors for sne ii p lead to speculate that these massive rsg progenitors may be forming black holes heralded by faint or non existent sn explosions see also type ii linear a rare type of cc sn it is perhaps not surprising that only one sn ii l sn 1980k has a pre sn image the analysis of which rules out massive rsg greater than about 33 analysis of the stellar population of the type ii l sn 1979c by determines a mass range of 34 for its progenitor at this point firm conclusions about the progenitors of sne ii l can not be made although early indications are that at least some do not arise from extremely massive stars type iin sn 2005gl described earlier in this review 33 as having a very massive 27 progenitor that exploded while in the lbv phase is the only example of an sn iin for which a progenitor has been detected in pre sn images whether such a massive progenitor is indicative of the class as a whole is not known type iib pre sn images exist for two events first sn 1993j in m81 where extensive analyses of pre sn and post sn images and spectra lead to the conclusion that a 35 star exploded in a binary system with a slightly less massive secondary surviving the explosion and references therein very recently the type iib sn 2008ax has provided a great opportunity to further investigate this rare class of cc sne since pre sn _hst_wfpc2 images exist in 36 a study by finds a curiously flat sed for the progenitor star which is impossible to reconcile with a single rsg but may be consistent with an early type w r wn class progenitor suggesting a progenitor star with a large 37 initial mass type ib c a well studied class with ten upper limits but no detections from analysis of pre sn images the lack of detections is surprising since it is commonly thought that at least some of the progenitors of sne ib c should be luminous single w r stars in addition to others perhaps arising from lower mass stars in binary systems while none of the non detections definitively rule out a w r progenitor demonstrates that it is quite unlikely at this point that all sne ib c come from them a summary of the current state of affairs of cc sn progenitor research via studies of pre sn images is provided by figure 6 the science of seeking sn progenitors has made tremendous strides in just the last ten years for the future i look with particular interest at the extremes as areas ripe for breakthrough discoveries since it is there that many of our most fundamental questions lie on the low mass end how will the lack of massive rsg progenitors for sne ii p be resolved are we seeing the first glimpse of the mass cutoff for direct collapse to black holes if so then how will this be reconciled with the _ very _ massive stars ie the other mass extreme that apparently do explode as sne iin or possibly iib and finally how does binarity influence all of these conclusions clearly we are just at the beginning stages of this exciting field of research and great advances will no doubt be made in the coming decade i thank the scientific organizing committee of the hot and cool bridging gaps in massive star evolution conference for inviting me to provide this review i thank seppo mattila for permitting reproduction of a figure from a recent paper and stephen smartt for allowing the use of figures in advance of publication of his annual reviews article on the topic "
"1009.3123-1"	"for about 20 years the problem of properties of short term changes of solar activity has been considered extensively many investigators studied the short term periodicities of the various indices of solar activity several periodicities were detected but the periodicities about 155 days and from the interval of 3 days 4 years are mentioned most often first of them was discovered by in the occurence rate of gamma ray flares detected by the gamma ray spectrometer aboard the _ solar maximum mission smm this periodicity was confirmed for other solar flares data and for the same time period it was also found in proton flares during solar cycles 19 and 20 but it was not found in the solar flares data during solar cycles 22 _ several autors confirmed above results for the daily sunspot area data studied the sunspot data from 18741984 she found the 155day periodicity in data records from 31 years this periodicity is always characteristic for one of the solar hemispheres the southern hemisphere for cycles 1215 and the northern hemisphere for cycles 1621 moreover it is only present during epochs of maximum activity in episodes of 13 years similarinvestigationswerecarriedoutby they applied the same power spectrum method as lean but the daily sunspot area data cycles 1221 were divided into 10 shorter time series the periodicities were searched for the frequency interval 57115 nhz 100200 days and for each of 10 time series the authors showed that the periodicity between 150160 days is statistically significant during all cycles from 16 to 21 the considered peaks were remained unaltered after removing the 11year cycle and applying the power spectrum analysis used the wavelet technique for the daily sunspot areas between 1874 and 1993 they determined the epochs of appearance of this periodicity and concluded that it presents around the maximum activity period in cycles 16 to 21 moreover the power of this periodicity started growing at cycle 19 decreased in cycles 20 and 21 and disappered after cycle 21 similaranalyseswerepresentedby but for sunspot number solar wind plasma interplanetary magnetic field and geomagnetic activity index 5 during 1964 2000 the sunspot number wavelet power of periods less than one year shows a cyclic evolution with the phase of the solar cyclethe 154day period is prominent and its strenth is stronger around the 1982 1984 interval in almost all solar wind parameters the existence of the 156day periodicity in sunspot data were confirmed by they considered the possible relation between the 475day 13year and 156day periodicities the 475day 13year periodicity was also detected in variations of the interplanetary magnetic field geomagnetic activity helioseismic data and in the solar wind speed concluded that the region of larger wavelet power shifts from 475day 13year period to 620day 17year period and then back to 475day 13year the periodicities from the interval 6 days 4 years have been considered from 1968 mentioned a 163month 490day periodicity in the sunspot numbers and in the geomagnetic data analysed the occurrence rate of major flares during solar cycles 19 they found a 18month 540day periodicity in flare rate of the norhern hemisphere confirmed this result for the 7 flare data for solar cycles 20 and 21 and found a peak in the power spectra near 510540 days found a 17month 510day periodicity of sunspot groups and their areas from 1969 to 1986 these authors concluded that the length of this period is variable and the reason of this periodicity is still not understood and obtained statistically significant peaks of power at around 158 days for daily sunspot data from 1923 1933 cycle 16 in this paper the problem of the existence of this periodicity for sunspot data from cycle 16 is considered the daily sunspot areas the mean sunspot areas per carrington rotation the monthly sunspot numbers and their fluctuations which are obtained after removing the 11year cycle are analysed in section 2 the properties of the power spectrum methods are described in section 3 a new approach to the problem of aliases in the power spectrum analysisis presented in section 4 numerical results of the new method of the diagnosis of an echo effect for sunspot area data are discussed in section 5 the problem of the existence of the periodicity of about 155 days during the maximum activity period for sunspot data from the whole solar disk and from each solar hemisphere separately is considered to find periodicities in a given time series the power spectrum analysis is applied in this papertwo methods are used the fast fourier transformation algorithm with the hamming window function fft and the blackman tukey bt power spectrum method the bt method is used for the diagnosis of the reasons of the existence of peaks which are obtained by the fft method the bt method consists in the smoothing of a cosine transform of an autocorrelation function using a 3point weighting average such an estimator is consistent and unbiased moreover the peaks are uncorrelated and their sum is a variance of a considered time series the main disadvantage of this method is a weak resolution of the periodogram points particularly for low frequences for example if the autocorrelation function is evaluated for 8 then the distribution points in the time domain are 9 thus it is obvious that this method should not be used for detecting low frequency periodicities with a fairly good resolution however because of an application of the autocorrelation function the bt method can be used to verify a reality of peaks which are computed using a method giving the better resolution for example the fft method it is valuable to remember that the power spectrum methods should be applied very carefully the difficulties in the interpretation of significant peaks could be caused by at least four effects a sampling of a continuos function an echo effect a contribution of long term periodicities and a random noise first effect exists because periodicities which are shorter than the sampling interval may mix with longer periodicities in result this effect can be reduced by an decrease of the sampling interval between observations the echo effect occurs when there is a latent harmonic of frequency 10 in the time series giving a spectral peak at 10 and also periodic terms of frequency 11 etc this may be detected by the autocorrelation function for time series with a large variance time series often contain long term periodicities that influence short term peaks they could rise periodogram s peaks at lower frequencies however it is also easy to notice the influence of the long term periodicities on short term peaks in the graphs of the autocorrelation functions this effect is observed for the time series of solar activity indexes which are limited by the 11year cycle to find statistically significant periodicitiesit is reasonable to use the autocorrelation function and the power spectrum method with a high resolution in the case of a stationary timeseries they give similar results moreover for a stationary time series with the mean zero the fourier transform is equivalent to the cosine transform of an autocorrelation function thus after a comparison of a periodogram with an appropriate autocorrelation function one can detect peaks which are in the graph of the first function and do not exist in the graph of the second function the reasons of their existence could be explained by the long term periodicities and the echo effect below method enables one to detect these effects solid line and the 95 confidence level basing on thered noise dotted line the periodogram values are presented on the left axis the lower curve illustrates the autocorrelation function of the same time series solid line the dotted lines represent two standard errors of the autocorrelation function the dashed horizontal line shows the zero level the autocorrelation values are shown in the right axis because the statistical tests indicate that the time series is a white noise the confidence level is not marked the method of the diagnosis of an echo effect in the power spectrum de consists in an analysis of a periodogram of a given time series computed using the bt method the bt method bases on the cosine transform of the autocorrelation function which creates peaks which are in the periodogram but not in the autocorrelation function the de method is used for peaks which are computed by the fft method with high resolution and are statistically significant the time series of sunspot activity indexes with the spacing interval one rotation or one month contain a markov type persistence which means a tendency for the successive values of the time series to remember their antecendent values thus i use a confidence level basing on the red noise of markov for the choice of the significant peaks of the periodogram computed by the fft method when a time series does not contain the markov type persistence i apply the fisher test and the kolmogorov smirnov test at the significance level 12 to verify a statistically significance of periodograms peaks the fisher test checks the null hypothesis that the time series is white noise agains the alternative hypothesis that the time series contains an added deterministic periodic component of unspecified frequency because the fisher test tends to be severe in rejecting peaks as insignificant the kolmogorov smirnov test is also used the de method analyses raw estimators of the power spectrum they are given as follows 13 for 14 where 15 for 16 17 is the length of the time series 18 and 19 is the mean value the first term of the estimator 20 is constant the second term takes two values depending on odd or even 21 which are not significant because 22 for large m thus the third term of 1 should be analysed looking for intervals of 23 for which 24 has the same sign and different signs one can find such parts of the function 25 which create the value 20 let the set of values of the independent variable of the autocorrelation function be called 26 and it can be divided into the sums of disjoint sets 27 where 28 29 30 31 32 33 34 35 36 37 3839 40 well the set 41 contains all integer values of 23 from the interval of 42 for which the autocorrelation function and the cosinus function with the period 43 are positive the index 44 indicates successive parts of the cosinus function for which the cosinuses of successive values of 23 have the same sign however sometimes the set 41 can be empty for example for 45 and 46 the set 47 should contain all 48 for which 49 and 50 but for such values of 23 the values of 51 are negative thus the set 47 is empty the periodogram values are presented on the left axis the lower curve illustrates the autocorrelation function of the same time series the autocorrelation values are shown in the right axis let us take into consideration all sets 52 53 and 41 which are not empty because numberings and power of these sets depend on the form of the autocorrelation function of the given time series it is impossible to establish them arbitrary thus the sets of appropriate indexes of the sets 52 53 and 41 are called 54 55 and 56 respectively for examplethe set 56 contains all 44 from the set 57 for which the sets 41 are not empty to separate quantitatively in the estimator 20 the positive contributions which are originated by the cases described by the formula 5 from the cases which are described by the formula 3 the following indexes are introduced 58 59 60 61 where 62 63 64 taking for the empty sets 53 and 41 the indices 65 and 66 equal zero the index 65 describes a percentage of the contribution of the case when 25 and 51 are positive to the positive part of the third term of the sum 1 the index 66 describes a similar contribution but for the case when the both 25 and 51 are simultaneously negative thanks to these one can decide which the positive or the negative values of the autocorrelation function have a larger contribution to the positive values of the estimator 20 when the difference 67 is positive the statement the 21th peak really exists can not be rejected thus the following formula should be satisfied 68 because the 21th peak could exist as a result of the echo effect it is necessary to verify the second condition 69 c_m the periodogram values are presented on the left axis the lower curve illustrates the autocorrelation function of the same time series solid line the dotted lines represent two standard errors of the autocorrelation function the dashed horizontal line shows the zero level the autocorrelation values are shown in the right axis to verify the implication 8 firstly it is necessary to evaluate the sets 41 for 70 of the values of 23 for which the autocorrelation function and the cosine function with the period 71 are positive and the sets 72 of values of 23 for which the autocorrelation function and the cosine function with the period 43 are negative secondly a percentage of the contribution of the sum of products of positive values of 25 and 51 to the sum of positive products of the values of 25 and 51 should be evaluated as a result the indexes 65 for each set41 where 44 is the index from the set 56 are obtained thirdly from all sets 41 such that 70 the set 73 for which the index 65 is the greatest should be chosen the implication 8 is true when the set 73 includes the considered period 43 this means that the greatest contribution of positive values of the autocorrelation function and positive cosines with the period 43 to the periodogram value 20 is caused by the sum of positive products of 74 for each 75m2k2mkm2k when the implication 8 is false the peak 20 is mainly created by the sum of positive products of 74 for each 76m2k 2mn m2k where 77 is a multiple or a divisor of 21 it is necessary to add that the de method should be applied to the periodograms peaks which probably exist because of the echo effect it enables one to find such parts of the autocorrelation function which have the significant contribution to the considered peak the fact that the conditions 7 and 8 are satisfied can unambiguously decide about the existence of the considered periodicity in the given time series but if at least one of them is not satisfied one can doubt about the existence of the considered periodicity thus in such cases the sentence the peak can not be treated as true should be used using the de methodit is necessary to remember about the power of the set 78 if 79 is too large errors of an autocorrelation function estimation appear they are caused by the finite length of the given time series and as a result additional peaks of the periodogram occur if 79 is too small there are less peaks because of a low resolution of the periodogram in applications80 is used in order to evaluate the value79 the fft method is used the periodograms computed by the bt and the fft method are compared the conformity of them enables one to obtain the value 79 the fft periodogram values are presented on the left axis the lower curve illustrates the bt periodogram of the same time series solid line and large black circles the bt periodogram values are shown in the right axis in this paper the sunspot activity data august 1923 october 1933 provided by the greenwich photoheliographic results gpr are analysed firstly i consider the monthly sunspot number data to eliminate the 11year trend from these data the consecutively smoothed monthly sunspot number 81 is subtracted from the monthly sunspot number 82 where the consecutive mean 83 is given by 84 the values 83 for 85 and 86 are calculated using additional data from last six months of cycle 15 and first six months of cycle 17 because of the north south asymmetry of various solar indices the sunspot activity is considered for each solar hemisphere separately analogously to the monthly sunspot numbers the time series of sunspot areas in the northern and southern hemispheres with the spacing interval 87 rotation are denoted in order to find periodicities the following time series are used 88 89 90 in the lower part of figure f1 the autocorrelation function of the time series for the northern hemisphere 88 is shown it is easy to notice that the prominent peak falls at 17 rotations interval 459 days and 25 for 91 rotations 81 162 days are significantly negative the periodogram of the time series 88 see the upper curve in figures f1 does not show the significant peaks at 92 rotations 135 162 days but there is the significant peak at 93 243 days the peaks at 94 are close to the peaks of the autocorrelation function thus the result obtained for the periodicity at about 0 days are contradict to the results obtained for the time series of daily sunspot areas for the southern hemisphere the lower curve in figure f2 25 for 95 rotations 54 189 days is not positive except 96 135 days for which 97 is not statistically significant the upper curve in figures f2 presents the periodogram of the time series 89 this time series does not contain a markov type persistence moreover the kolmogorov smirnov test and the fisher test do not reject a null hypothesis that the time series is a white noise only this means that the time series do not contain an added deterministic periodic component of unspecified frequency the autocorrelation function of the time series 90 the lower curve in figure f3 has only one statistically significant peak for 98 months 480 days and negative values for 99 months 90 390 days however the periodogram of this time series the upper curve in figure f3 has two significant peaks the first at 152 and the second at 53 months 456 159 days thus the periodogram contains the significant peak although the autocorrelation function has the negative value at 100 months to explainthese problems two following time series of daily sunspot areas are considered 101 102 where 103 the values 104 for 105 and 106 are calculated using additional daily data from the solar cycles 15 and 17 and the cosine function for 45 the period at about 154 days the horizontal line dotted line shows the zero level the vertical dotted lines evaluate the intervals where the sets 107 for 108 are searched the percentage values show the index 65 for each 41 for the time series 102 in parentheses for the time series 101 in the right bottom cornerthe values of 65 for the time series 102 for 109 are written the 500day period the comparison of the functions 25 of the time series 101 the lower curve in figure f4 and 102 the lower curve in figure f5 suggests that the positive values of the function 110 of the time series 101 in the interval of 111 days could be caused by the 11year cycle this effect is not visible in the case of periodograms of the both time series computed using the fft method see the upper curves in figures f4 and f5 or the bt method see the lower curve in figure f6 moreover the periodogram of the time series 102 has the significant values at 112 days but the autocorrelation function is negative at these points showed that the lomb scargle periodograms for the both time series see figures 7 a c have a peak at 1588 days which stands over the fap level by a significant amount using the de method the above discrepancies are obvious to establish the 79 value the periodograms computed by the fft andthe bt methods are shown in figure f6 the upper and the lower curve respectively for 46 and for periods less than 166 days there is a good comformity of the both periodograms but for periods greater than 166 days the points of the bt periodogram are not linked because the bt periodogram has much worse resolution than the fft periodogram no one know how to do it for 46 and 113the value of 21 is 13 71153 the inequality 7 is satisfied because 114 this means that the value of 115 is mainly created by positive values of the autocorrelation function the implication 8 needs an evaluation of the greatest value of the index 65 where 70 but the solar data contain the most prominent period for 116 days because of the solar rotation thus although 117 for each 118 all sets 41 see 5 and 6 without the set 119 see 4 which contains 120 are considered this situation is presented in figure f7 in this figuretwo curves 121 and 122 are plotted the vertical dotted lines evaluate the intervals where the sets 107 for 123 are searched for such 41 two numbersare written in parentheses the value of 65 for the time series 101 and above it the value of 65 for the time series 102 to make this figure clear the curves are plotted for the set 124 only in the right bottom corner information about the values of 65 for the time series 102 for 109 are written the implication 8 is not true because 125 for 126 therefore 43153 c_6423500 moreover the autocorrelation function for 127 is negative and the set 128 is empty thus 129 on the basis of these information one can state that the periodogram peak at 130 days of the time series 102 exists because of positive 25 but for 23 from the intervals which do not contain this period looking at the values of 65 of the time series 101 one can notice that they decrease when 23 increases until 131 this indicates that when 23 increases the contribution of the 11year cycle to the peaks of the periodogram decreases an increase of the value of 65 is for 132 for the both time series although the contribution of the 11year cycle for the time series 101 is insignificant thus this part of the autocorrelation function 133 for the time series 102 influences the 21th peak of the periodogram this suggests that the periodicity at about 155 days is a harmonic of the periodicity from the interval of 1 days solid line and consecutively smoothed sunspot areas of the one rotation time interval 134 dotted line both indexes are presented on the left axis the lower curve illustrates fluctuations of the sunspot areas 135 the dotted and dashed horizontal lines represent levels zero and 136 respectively the fluctuations are shown on the right axis the described reasoning can be carried out for other values of the periodogram for example the condition 8 is not satisfied for 137 250 222 200 days moreover the autocorrelation function at these points is negative these suggest that there are not a true periodicity in the interval of 200 250 days it is difficult to decide about the existence of the periodicities for 138 333 days and 139 286 days on the basis of above analysis the implication 8 is not satisfied for 139 and the condition 7 is not satisfied for 138 although the function 25 of the time series 102 is significantly positive for 140 the conditions 7 and 8 are satisfied for 141 figure f8 and 142 therefore it is possible to exist the periodicity from the interval of 1 days similar results were also obtained by for daily sunspot numbers and daily sunspot areas she considered the means of three periodograms of these indexes for data from 143 years and found statistically significant peaks from the interval of 1 see figure 2 studied sunspot areas from 1876 1999 and sunspot numbers from 1749 2001 with the help of the wavelet transform they pointed out that the 154 158day period could be the third harmonic of the 13year 475day period moreover the both periods fluctuate considerably with time being stronger during stronger sunspot cycles therefore the wavelet analysis suggests a common origin of the both periodicities this conclusion confirms the de method result which indicates that the periodogram peak at 144 days is an alias of the periodicity from the interval of 1 in order to verify the existence of the periodicity at about 155 days i consider the following time series 145 146 147 the value 134 is calculated analogously to 83 see sect the values 148 and 149 are evaluated from the formula 9 in the upper part of figure f9 the time series of sunspot areas 150 of the one rotation time interval from the whole solar disk and the time series of consecutively smoothed sunspot areas 151are showed in the lower part of figure f9 the time series of sunspot area fluctuations 145 is presented on the basis of these data the maximum activity period of cycle 16 is evaluated it is an interval between two strongest fluctuations ea 152 rotations the length of the time interval 153 is 54 rotations if the about 0day 6 solar rotations periodicity existed in this time interval and it was characteristic for strong fluctuations from this time interval 10 local maxima in the set of 154 would be seen then it should be necessary to find such a value of p for which 155 for 156 and the number of the local maxima of these values is 10 as it can be seen in the lower part of figure f9 this is for the case of 157 in this figure the dashed horizontal line is the level of 158 figure f10 presents nine time distances among the successive fluctuation local maxima and the horizontal line represents the 6rotation periodicity it is immediately apparent that the dispersion of these points is 10 and it is difficult to find even few points which oscillate around the value of 6 such an analysis was carried out for smaller and larger 136 and the results were similar therefore the fact that the about 0day periodicity exists in the time series of sunspot area fluctuations during the maximum activity period is questionable the horizontal line represents the 6rotation 162day period to verify again the existence of the about 0day periodicity during the maximum activity period in each solar hemisphere separately the time series 88 and 89 were also cut down to the maximum activity period january 1925december 1930 the comparison of the autocorrelation functions of these time series with the appriopriate autocorrelation functions of the time series 88 and 89 which are computed for the whole 11year cycle the lower curves of figures f1 and f2 indicates that there are not significant differences between them especially for 235 and 6 rotations 135 and 162 days this conclusion is confirmed by the analysis of the time series 146 for the maximum activity period the autocorrelation function the lower curve of figure f11 is negative for the interval of 57 173 days but the resolution of the periodogram is too low to find the significant peak at 159 days the autocorrelation function gives the same result as for daily sunspot area fluctuations from the whole solar disk 160 see also the lower curve of figures f5 in the case ofthe time series 89 161 is zero for the fluctuations from the whole solar cycle and it is almost zero 162 for the fluctuations from the maximum activity period the value 163 is negative similarly to the case of the northern hemisphere the autocorrelation function and the periodogram of southern hemisphere daily sunspot area fluctuations from the maximum activity period 147 are computed see figure f12 the autocorrelation function has the statistically significant positive peak in the interval of 155 165 days but the periodogram has too low resolution to decide about the possible periodicities the correlative analysis indicates that there are positive fluctuations with time distances about 0 days in the maximum activity period the results of the analyses of the time series of sunspot area fluctuations from the maximum activity period are contradict with the conclusions of she uses the power spectrum analysis only the periodogram of daily sunspot fluctuations contains peaks which could be harmonics or subharmonics of the true periodicities they could be treated as real periodicities this effect is not visible for sunspot data of the one rotation time interval but averaging could lose true periodicities this is observed for data from the southern hemisphere there is the about 0day peak in the autocorrelation function of daily fluctuations but the correlation for data of the one rotation interval is almost zero or negative at the points 164 and 6 rotations thus it is reasonable to research both time series together using the correlative and the power spectrum analyses the following results are obtained 1 a new method of the detection of statistically significant peaks of the periodograms enables one to identify aliases in the periodogram 2 two effects cause the existence of the peak of the periodogram of the time series of sunspot area fluctuations at about 0 days the first is caused by the 27day periodicity which probably creates the 162day periodicity it is a subharmonic frequency of the 27day periodicity and the second is caused by statistically significant positive values of the autocorrelation function from the intervals of 165 and 166 days the existence of the periodicity of about 0 days of the time series of sunspot area fluctuations and sunspot area fluctuations from the northern hemisphere during the maximum activity period is questionable the autocorrelation analysis of the time series of sunspot area fluctuations from the southern hemisphere indicates that the periodicity of about 155 days exists during the maximum activity period i appreciate valuable comments from professor j jakimiec "
"1009.3123"	"for about 20 years the problem of properties of short term changes of solar activity has been considered extensively many investigators studied the short term periodicities of the various indices of solar activity several periodicities were detected but the periodicities about 155 days and from the interval of 3 days 4 years are mentioned most often first of them was discovered by in the occurence rate of gamma ray flares detected by the gamma ray spectrometer aboard the _ solar maximum mission smm this periodicity was confirmed for other solar flares data and for the same time period it was also found in proton flares during solar cycles 19 and 20 but it was not found in the solar flares data during solar cycles 22 _ several autors confirmed above results for the daily sunspot area data studied the sunspot data from 18741984 she found the 155day periodicity in data records from 31 years this periodicity is always characteristic for one of the solar hemispheres the southern hemisphere for cycles 1215 and the northern hemisphere for cycles 1621 moreover it is only present during epochs of maximum activity in episodes of 13 years similarinvestigationswerecarriedoutby they applied the same power spectrum method as lean but the daily sunspot area data cycles 1221 were divided into 10 shorter time series the periodicities were searched for the frequency interval 57115 nhz 100200 days and for each of 10 time series the authors showed that the periodicity between 150160 days is statistically significant during all cycles from 16 to 21 the considered peaks were remained unaltered after removing the 11year cycle and applying the power spectrum analysis used the wavelet technique for the daily sunspot areas between 1874 and 1993 they determined the epochs of appearance of this periodicity and concluded that it presents around the maximum activity period in cycles 16 to 21 moreover the power of this periodicity started growing at cycle 19 decreased in cycles 20 and 21 and disappered after cycle 21 similaranalyseswerepresentedby but for sunspot number solar wind plasma interplanetary magnetic field and geomagnetic activity index 5 during 1964 2000 the sunspot number wavelet power of periods less than one year shows a cyclic evolution with the phase of the solar cyclethe 154day period is prominent and its strenth is stronger around the 1982 1984 interval in almost all solar wind parameters the existence of the 156day periodicity in sunspot data were confirmed by they considered the possible relation between the 475day 13year and 156day periodicities the 475day 13year periodicity was also detected in variations of the interplanetary magnetic field geomagnetic activity helioseismic data and in the solar wind speed concluded that the region of larger wavelet power shifts from 475day 13year period to 620day 17year period and then back to 475day 13year the periodicities from the interval 6 days 4 years have been considered from 1968 mentioned a 163month 490day periodicity in the sunspot numbers and in the geomagnetic data analysed the occurrence rate of major flares during solar cycles 19 they found a 18month 540day periodicity in flare rate of the norhern hemisphere confirmed this result for the 7 flare data for solar cycles 20 and 21 and found a peak in the power spectra near 510540 days found a 17month 510day periodicity of sunspot groups and their areas from 1969 to 1986 these authors concluded that the length of this period is variable and the reason of this periodicity is still not understood and obtained statistically significant peaks of power at around 158 days for daily sunspot data from 1923 1933 cycle 16 in this paper the problem of the existence of this periodicity for sunspot data from cycle 16 is considered the daily sunspot areas the mean sunspot areas per carrington rotation the monthly sunspot numbers and their fluctuations which are obtained after removing the 11year cycle are analysed in section 2 the properties of the power spectrum methods are described in section 3 a new approach to the problem of aliases in the power spectrum analysisis presented in section 4 numerical results of the new method of the diagnosis of an echo effect for sunspot area data are discussed in section 5 the problem of the existence of the periodicity of about 155 days during the maximum activity period for sunspot data from the whole solar disk and from each solar hemisphere separately is considered to find periodicities in a given time series the power spectrum analysis is applied in this papertwo methods are used the fast fourier transformation algorithm with the hamming window function fft and the blackman tukey bt power spectrum method the bt method is used for the diagnosis of the reasons of the existence of peaks which are obtained by the fft method the bt method consists in the smoothing of a cosine transform of an autocorrelation function using a 3point weighting average such an estimator is consistent and unbiased moreover the peaks are uncorrelated and their sum is a variance of a considered time series the main disadvantage of this method is a weak resolution of the periodogram points particularly for low frequences for example if the autocorrelation function is evaluated for 8 then the distribution points in the time domain are 9 thus it is obvious that this method should not be used for detecting low frequency periodicities with a fairly good resolution however because of an application of the autocorrelation function the bt method can be used to verify a reality of peaks which are computed using a method giving the better resolution for example the fft method it is valuable to remember that the power spectrum methods should be applied very carefully the difficulties in the interpretation of significant peaks could be caused by at least four effects a sampling of a continuos function an echo effect a contribution of long term periodicities and a random noise first effect exists because periodicities which are shorter than the sampling interval may mix with longer periodicities in result this effect can be reduced by an decrease of the sampling interval between observations the echo effect occurs when there is a latent harmonic of frequency 10 in the time series giving a spectral peak at 10 and also periodic terms of frequency 11 etc this may be detected by the autocorrelation function for time series with a large variance time series often contain long term periodicities that influence short term peaks they could rise periodogram s peaks at lower frequencies however it is also easy to notice the influence of the long term periodicities on short term peaks in the graphs of the autocorrelation functions this effect is observed for the time series of solar activity indexes which are limited by the 11year cycle to find statistically significant periodicitiesit is reasonable to use the autocorrelation function and the power spectrum method with a high resolution in the case of a stationary timeseries they give similar results moreover for a stationary time series with the mean zero the fourier transform is equivalent to the cosine transform of an autocorrelation function thus after a comparison of a periodogram with an appropriate autocorrelation function one can detect peaks which are in the graph of the first function and do not exist in the graph of the second function the reasons of their existence could be explained by the long term periodicities and the echo effect below method enables one to detect these effects solid line and the 95 confidence level basing on thered noise dotted line the periodogram values are presented on the left axis the lower curve illustrates the autocorrelation function of the same time series solid line the dotted lines represent two standard errors of the autocorrelation function the dashed horizontal line shows the zero level the autocorrelation values are shown in the right axis because the statistical tests indicate that the time series is a white noise the confidence level is not marked the method of the diagnosis of an echo effect in the power spectrum de consists in an analysis of a periodogram of a given time series computed using the bt method the bt method bases on the cosine transform of the autocorrelation function which creates peaks which are in the periodogram but not in the autocorrelation function the de method is used for peaks which are computed by the fft method with high resolution and are statistically significant the time series of sunspot activity indexes with the spacing interval one rotation or one month contain a markov type persistence which means a tendency for the successive values of the time series to remember their antecendent values thus i use a confidence level basing on the red noise of markov for the choice of the significant peaks of the periodogram computed by the fft method when a time series does not contain the markov type persistence i apply the fisher test and the kolmogorov smirnov test at the significance level 12 to verify a statistically significance of periodograms peaks the fisher test checks the null hypothesis that the time series is white noise agains the alternative hypothesis that the time series contains an added deterministic periodic component of unspecified frequency because the fisher test tends to be severe in rejecting peaks as insignificant the kolmogorov smirnov test is also used the de method analyses raw estimators of the power spectrum they are given as follows 13 for 14 where 15 for 16 17 is the length of the time series 18 and 19 is the mean value the first term of the estimator 20 is constant the second term takes two values depending on odd or even 21 which are not significant because 22 for large m thus the third term of 1 should be analysed looking for intervals of 23 for which 24 has the same sign and different signs one can find such parts of the function 25 which create the value 20 let the set of values of the independent variable of the autocorrelation function be called 26 and it can be divided into the sums of disjoint sets 27 where 28 29 30 31 32 33 34 35 36 37 3839 40 well the set 41 contains all integer values of 23 from the interval of 42 for which the autocorrelation function and the cosinus function with the period 43 are positive the index 44 indicates successive parts of the cosinus function for which the cosinuses of successive values of 23 have the same sign however sometimes the set 41 can be empty for example for 45 and 46 the set 47 should contain all 48 for which 49 and 50 but for such values of 23 the values of 51 are negative thus the set 47 is empty the periodogram values are presented on the left axis the lower curve illustrates the autocorrelation function of the same time series the autocorrelation values are shown in the right axis let us take into consideration all sets 52 53 and 41 which are not empty because numberings and power of these sets depend on the form of the autocorrelation function of the given time series it is impossible to establish them arbitrary thus the sets of appropriate indexes of the sets 52 53 and 41 are called 54 55 and 56 respectively for examplethe set 56 contains all 44 from the set 57 for which the sets 41 are not empty to separate quantitatively in the estimator 20 the positive contributions which are originated by the cases described by the formula 5 from the cases which are described by the formula 3 the following indexes are introduced 58 59 60 61 where 62 63 64 taking for the empty sets 53 and 41 the indices 65 and 66 equal zero the index 65 describes a percentage of the contribution of the case when 25 and 51 are positive to the positive part of the third term of the sum 1 the index 66 describes a similar contribution but for the case when the both 25 and 51 are simultaneously negative thanks to these one can decide which the positive or the negative values of the autocorrelation function have a larger contribution to the positive values of the estimator 20 when the difference 67 is positive the statement the 21th peak really exists can not be rejected thus the following formula should be satisfied 68 because the 21th peak could exist as a result of the echo effect it is necessary to verify the second condition 69 c_m the periodogram values are presented on the left axis the lower curve illustrates the autocorrelation function of the same time series solid line the dotted lines represent two standard errors of the autocorrelation function the dashed horizontal line shows the zero level the autocorrelation values are shown in the right axis to verify the implication 8 firstly it is necessary to evaluate the sets 41 for 70 of the values of 23 for which the autocorrelation function and the cosine function with the period 71 are positive and the sets 72 of values of 23 for which the autocorrelation function and the cosine function with the period 43 are negative secondly a percentage of the contribution of the sum of products of positive values of 25 and 51 to the sum of positive products of the values of 25 and 51 should be evaluated as a result the indexes 65 for each set41 where 44 is the index from the set 56 are obtained thirdly from all sets 41 such that 70 the set 73 for which the index 65 is the greatest should be chosen the implication 8 is true when the set 73 includes the considered period 43 this means that the greatest contribution of positive values of the autocorrelation function and positive cosines with the period 43 to the periodogram value 20 is caused by the sum of positive products of 74 for each 75m2k2mkm2k when the implication 8 is false the peak 20 is mainly created by the sum of positive products of 74 for each 76m2k 2mn m2k where 77 is a multiple or a divisor of 21 it is necessary to add that the de method should be applied to the periodograms peaks which probably exist because of the echo effect it enables one to find such parts of the autocorrelation function which have the significant contribution to the considered peak the fact that the conditions 7 and 8 are satisfied can unambiguously decide about the existence of the considered periodicity in the given time series but if at least one of them is not satisfied one can doubt about the existence of the considered periodicity thus in such cases the sentence the peak can not be treated as true should be used using the de methodit is necessary to remember about the power of the set 78 if 79 is too large errors of an autocorrelation function estimation appear they are caused by the finite length of the given time series and as a result additional peaks of the periodogram occur if 79 is too small there are less peaks because of a low resolution of the periodogram in applications80 is used in order to evaluate the value79 the fft method is used the periodograms computed by the bt and the fft method are compared the conformity of them enables one to obtain the value 79 the fft periodogram values are presented on the left axis the lower curve illustrates the bt periodogram of the same time series solid line and large black circles the bt periodogram values are shown in the right axis in this paper the sunspot activity data august 1923 october 1933 provided by the greenwich photoheliographic results gpr are analysed firstly i consider the monthly sunspot number data to eliminate the 11year trend from these data the consecutively smoothed monthly sunspot number 81 is subtracted from the monthly sunspot number 82 where the consecutive mean 83 is given by 84 the values 83 for 85 and 86 are calculated using additional data from last six months of cycle 15 and first six months of cycle 17 because of the north south asymmetry of various solar indices the sunspot activity is considered for each solar hemisphere separately analogously to the monthly sunspot numbers the time series of sunspot areas in the northern and southern hemispheres with the spacing interval 87 rotation are denoted in order to find periodicities the following time series are used 88 89 90 in the lower part of figure f1 the autocorrelation function of the time series for the northern hemisphere 88 is shown it is easy to notice that the prominent peak falls at 17 rotations interval 459 days and 25 for 91 rotations 81 162 days are significantly negative the periodogram of the time series 88 see the upper curve in figures f1 does not show the significant peaks at 92 rotations 135 162 days but there is the significant peak at 93 243 days the peaks at 94 are close to the peaks of the autocorrelation function thus the result obtained for the periodicity at about 0 days are contradict to the results obtained for the time series of daily sunspot areas for the southern hemisphere the lower curve in figure f2 25 for 95 rotations 54 189 days is not positive except 96 135 days for which 97 is not statistically significant the upper curve in figures f2 presents the periodogram of the time series 89 this time series does not contain a markov type persistence moreover the kolmogorov smirnov test and the fisher test do not reject a null hypothesis that the time series is a white noise only this means that the time series do not contain an added deterministic periodic component of unspecified frequency the autocorrelation function of the time series 90 the lower curve in figure f3 has only one statistically significant peak for 98 months 480 days and negative values for 99 months 90 390 days however the periodogram of this time series the upper curve in figure f3 has two significant peaks the first at 152 and the second at 53 months 456 159 days thus the periodogram contains the significant peak although the autocorrelation function has the negative value at 100 months to explainthese problems two following time series of daily sunspot areas are considered 101 102 where 103 the values 104 for 105 and 106 are calculated using additional daily data from the solar cycles 15 and 17 and the cosine function for 45 the period at about 154 days the horizontal line dotted line shows the zero level the vertical dotted lines evaluate the intervals where the sets 107 for 108 are searched the percentage values show the index 65 for each 41 for the time series 102 in parentheses for the time series 101 in the right bottom cornerthe values of 65 for the time series 102 for 109 are written the 500day period the comparison of the functions 25 of the time series 101 the lower curve in figure f4 and 102 the lower curve in figure f5 suggests that the positive values of the function 110 of the time series 101 in the interval of 111 days could be caused by the 11year cycle this effect is not visible in the case of periodograms of the both time series computed using the fft method see the upper curves in figures f4 and f5 or the bt method see the lower curve in figure f6 moreover the periodogram of the time series 102 has the significant values at 112 days but the autocorrelation function is negative at these points showed that the lomb scargle periodograms for the both time series see figures 7 a c have a peak at 1588 days which stands over the fap level by a significant amount using the de method the above discrepancies are obvious to establish the 79 value the periodograms computed by the fft andthe bt methods are shown in figure f6 the upper and the lower curve respectively for 46 and for periods less than 166 days there is a good comformity of the both periodograms but for periods greater than 166 days the points of the bt periodogram are not linked because the bt periodogram has much worse resolution than the fft periodogram no one know how to do it for 46 and 113the value of 21 is 13 71153 the inequality 7 is satisfied because 114 this means that the value of 115 is mainly created by positive values of the autocorrelation function the implication 8 needs an evaluation of the greatest value of the index 65 where 70 but the solar data contain the most prominent period for 116 days because of the solar rotation thus although 117 for each 118 all sets 41 see 5 and 6 without the set 119 see 4 which contains 120 are considered this situation is presented in figure f7 in this figuretwo curves 121 and 122 are plotted the vertical dotted lines evaluate the intervals where the sets 107 for 123 are searched for such 41 two numbersare written in parentheses the value of 65 for the time series 101 and above it the value of 65 for the time series 102 to make this figure clear the curves are plotted for the set 124 only in the right bottom corner information about the values of 65 for the time series 102 for 109 are written the implication 8 is not true because 125 for 126 therefore 43153 c_6423500 moreover the autocorrelation function for 127 is negative and the set 128 is empty thus 129 on the basis of these information one can state that the periodogram peak at 130 days of the time series 102 exists because of positive 25 but for 23 from the intervals which do not contain this period looking at the values of 65 of the time series 101 one can notice that they decrease when 23 increases until 131 this indicates that when 23 increases the contribution of the 11year cycle to the peaks of the periodogram decreases an increase of the value of 65 is for 132 for the both time series although the contribution of the 11year cycle for the time series 101 is insignificant thus this part of the autocorrelation function 133 for the time series 102 influences the 21th peak of the periodogram this suggests that the periodicity at about 155 days is a harmonic of the periodicity from the interval of 1 days solid line and consecutively smoothed sunspot areas of the one rotation time interval 134 dotted line both indexes are presented on the left axis the lower curve illustrates fluctuations of the sunspot areas 135 the dotted and dashed horizontal lines represent levels zero and 136 respectively the fluctuations are shown on the right axis the described reasoning can be carried out for other values of the periodogram for example the condition 8 is not satisfied for 137 250 222 200 days moreover the autocorrelation function at these points is negative these suggest that there are not a true periodicity in the interval of 200 250 days it is difficult to decide about the existence of the periodicities for 138 333 days and 139 286 days on the basis of above analysis the implication 8 is not satisfied for 139 and the condition 7 is not satisfied for 138 although the function 25 of the time series 102 is significantly positive for 140 the conditions 7 and 8 are satisfied for 141 figure f8 and 142 therefore it is possible to exist the periodicity from the interval of 1 days similar results were also obtained by for daily sunspot numbers and daily sunspot areas she considered the means of three periodograms of these indexes for data from 143 years and found statistically significant peaks from the interval of 1 see figure 2 studied sunspot areas from 1876 1999 and sunspot numbers from 1749 2001 with the help of the wavelet transform they pointed out that the 154 158day period could be the third harmonic of the 13year 475day period moreover the both periods fluctuate considerably with time being stronger during stronger sunspot cycles therefore the wavelet analysis suggests a common origin of the both periodicities this conclusion confirms the de method result which indicates that the periodogram peak at 144 days is an alias of the periodicity from the interval of 1 in order to verify the existence of the periodicity at about 155 days i consider the following time series 145 146 147 the value 134 is calculated analogously to 83 see sect the values 148 and 149 are evaluated from the formula 9 in the upper part of figure f9 the time series of sunspot areas 150 of the one rotation time interval from the whole solar disk and the time series of consecutively smoothed sunspot areas 151are showed in the lower part of figure f9 the time series of sunspot area fluctuations 145 is presented on the basis of these data the maximum activity period of cycle 16 is evaluated it is an interval between two strongest fluctuations ea 152 rotations the length of the time interval 153 is 54 rotations if the about 0day 6 solar rotations periodicity existed in this time interval and it was characteristic for strong fluctuations from this time interval 10 local maxima in the set of 154 would be seen then it should be necessary to find such a value of p for which 155 for 156 and the number of the local maxima of these values is 10 as it can be seen in the lower part of figure f9 this is for the case of 157 in this figure the dashed horizontal line is the level of 158 figure f10 presents nine time distances among the successive fluctuation local maxima and the horizontal line represents the 6rotation periodicity it is immediately apparent that the dispersion of these points is 10 and it is difficult to find even few points which oscillate around the value of 6 such an analysis was carried out for smaller and larger 136 and the results were similar therefore the fact that the about 0day periodicity exists in the time series of sunspot area fluctuations during the maximum activity period is questionable the horizontal line represents the 6rotation 162day period to verify again the existence of the about 0day periodicity during the maximum activity period in each solar hemisphere separately the time series 88 and 89 were also cut down to the maximum activity period january 1925december 1930 the comparison of the autocorrelation functions of these time series with the appriopriate autocorrelation functions of the time series 88 and 89 which are computed for the whole 11year cycle the lower curves of figures f1 and f2 indicates that there are not significant differences between them especially for 235 and 6 rotations 135 and 162 days this conclusion is confirmed by the analysis of the time series 146 for the maximum activity period the autocorrelation function the lower curve of figure f11 is negative for the interval of 57 173 days but the resolution of the periodogram is too low to find the significant peak at 159 days the autocorrelation function gives the same result as for daily sunspot area fluctuations from the whole solar disk 160 see also the lower curve of figures f5 in the case ofthe time series 89 161 is zero for the fluctuations from the whole solar cycle and it is almost zero 162 for the fluctuations from the maximum activity period the value 163 is negative similarly to the case of the northern hemisphere the autocorrelation function and the periodogram of southern hemisphere daily sunspot area fluctuations from the maximum activity period 147 are computed see figure f12 the autocorrelation function has the statistically significant positive peak in the interval of 155 165 days but the periodogram has too low resolution to decide about the possible periodicities the correlative analysis indicates that there are positive fluctuations with time distances about 0 days in the maximum activity period the results of the analyses of the time series of sunspot area fluctuations from the maximum activity period are contradict with the conclusions of she uses the power spectrum analysis only the periodogram of daily sunspot fluctuations contains peaks which could be harmonics or subharmonics of the true periodicities they could be treated as real periodicities this effect is not visible for sunspot data of the one rotation time interval but averaging could lose true periodicities this is observed for data from the southern hemisphere there is the about 0day peak in the autocorrelation function of daily fluctuations but the correlation for data of the one rotation interval is almost zero or negative at the points 164 and 6 rotations thus it is reasonable to research both time series together using the correlative and the power spectrum analyses the following results are obtained 1 a new method of the detection of statistically significant peaks of the periodograms enables one to identify aliases in the periodogram 2 two effects cause the existence of the peak of the periodogram of the time series of sunspot area fluctuations at about 0 days the first is caused by the 27day periodicity which probably creates the 162day periodicity it is a subharmonic frequency of the 27day periodicity and the second is caused by statistically significant positive values of the autocorrelation function from the intervals of 165 and 166 days the existence of the periodicity of about 0 days of the time series of sunspot area fluctuations and sunspot area fluctuations from the northern hemisphere during the maximum activity period is questionable the autocorrelation analysis of the time series of sunspot area fluctuations from the southern hemisphere indicates that the periodicity of about 155 days exists during the maximum activity period i appreciate valuable comments from professor j jakimiec "