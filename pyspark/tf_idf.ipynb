{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import HashingTF, IDF\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_file(x):\n",
    "    value=x.value.split('\\t')\n",
    "    return (value[0], value[1].split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/03/18 08:37:09 WARN Utils: Your hostname, LAPTOP-MOK83Q9I resolves to a loopback address: 127.0.1.1; using 172.26.70.148 instead (on interface eth0)\n",
      "22/03/18 08:37:09 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/03/18 08:37:11 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName('SparkByExamples.com').getOrCreate()\n",
    "df = spark.read.text('cleaned.txt')\n",
    "rdd = df.rdd.map(lambda x: split_file(x))\n",
    "df2 = rdd.toDF().withColumnRenamed('_2', 'content').withColumnRenamed('_1', 'id')\n",
    "\n",
    "hashingTF = HashingTF(inputCol=\"content\", outputCol='features')\n",
    "hashingTF.setNumFeatures(1000)\n",
    "\n",
    "tf = hashingTF.transform(df2)\n",
    "\n",
    "idf = IDF()\n",
    "idf.setInputCol('features')\n",
    "idf.setOutputCol('idf')\n",
    "model = idf.fit(tf)\n",
    "tf_idf = model.transform(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[id: string, content: array<string>, features: vector, idf: vector]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf.rdd.cartesian()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as psf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 4:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+-------------------+\n",
      "|          i|            j|                dot|\n",
      "+-----------+-------------+-------------------+\n",
      "|\"0801.1913\"|  \"0806.3537\"| 0.1413471072354091|\n",
      "|\"0801.1913\"|  \"0807.5065\"|0.14126193913291646|\n",
      "|\"0801.1913\"|  \"0809.0691\"|0.16296139678695296|\n",
      "|\"0801.1913\"|  \"0811.2070\"|0.12773448168976206|\n",
      "|\"0801.1913\"|  \"0907.5423\"| 0.1542216397172733|\n",
      "|\"0801.1913\"|  \"0908.1812\"|0.08835149491310022|\n",
      "|\"0801.1913\"|  \"0909.1602\"|0.10423572180671294|\n",
      "|\"0801.1913\"|  \"0911.1170\"|0.13923590897626348|\n",
      "|\"0801.1913\"|  \"1001.0199\"| 0.1435384027466791|\n",
      "|\"0801.1913\"|  \"1004.5347\"| 0.1301095462729346|\n",
      "|\"0801.1913\"|  \"1009.3123\"|0.12919244660378096|\n",
      "|\"0801.1913\"|\"1009.3123-1\"|0.12919244660378096|\n",
      "|\"0801.1913\"|  \"1111.4135\"|0.17119358828601075|\n",
      "|\"0801.1913\"|  \"1202.0294\"|0.16028872885185458|\n",
      "|\"0801.1913\"|  \"1212.0086\"| 0.2421147626224124|\n",
      "|\"0801.1913\"|  \"1307.2735\"|0.12886586905122766|\n",
      "|\"0801.1913\"|  \"1309.3865\"|0.14166832031039753|\n",
      "|\"0801.1913\"|  \"1311.0649\"|0.22637302810818294|\n",
      "|\"0801.1913\"|  \"1401.4918\"| 0.2428985879792362|\n",
      "|\"0801.1913\"|  \"1412.2508\"|0.16329606558134505|\n",
      "+-----------+-------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "dot_udf = psf.udf(lambda x,y: float(x.dot(y)/(x.norm(2) * y.norm(2))), DoubleType())\n",
    "result = tf_idf.alias(\"i\").join(tf_idf.alias(\"j\"), psf.col(\"i.id\") < psf.col(\"j.id\"))\\\n",
    "    .select(\n",
    "        psf.col(\"i.id\").alias(\"i\"), \n",
    "        psf.col(\"j.id\").alias(\"j\"), \n",
    "        dot_udf(\"i.idf\", \"j.idf\").alias(\"dot\"))\\\n",
    "    .sort(\"i\", \"j\")\n",
    "\n",
    "result.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['id', 'sim_score']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for i, x in enumerate(tf_idf.take(5)):\n",
    "    sim_score_list = []\n",
    "    for y in tf_idf.take(5):\n",
    "        sim_score = x.idf.dot(y.idf) / (x.idf.norm(2) * y.idf.norm(2))\n",
    "        sim_score_list.append(float(sim_score))\n",
    "    data.append((x.id, sim_score_list))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(id='\"hep-ph0205344\"', sim_score=[1.0, 0.12423407925986085, 0.24118939728349553, 0.24687892577787154, 0.11215675867134679])]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_df = spark.createDataFrame(data).toDF(*columns)\n",
    "sim_df.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[id: string, content: array<string>, features: vector, idf: vector]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>content</th>\n",
       "      <th>features</th>\n",
       "      <th>idf</th>\n",
       "      <th>sim_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"hep-ph0205344\"</td>\n",
       "      <td>[\"the, standard, model, is, greatly, successfu...</td>\n",
       "      <td>(0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 0.0, ...</td>\n",
       "      <td>(0.0, 0.2947995402206448, 1.1420974006078486, ...</td>\n",
       "      <td>[1.0, 0.12423407925986085, 0.24118939728349553...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"astro-ph0612210\"</td>\n",
       "      <td>[\"the, study, of, the, formation, and, evoluti...</td>\n",
       "      <td>(0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, ...</td>\n",
       "      <td>(0.0, 0.8843986206619344, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.12423407925986085, 1.0, 0.11745402368601676...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"1401.4918\"</td>\n",
       "      <td>[\"the, dynamical, density, matrix, renormaliza...</td>\n",
       "      <td>(0.0, 8.0, 0.0, 4.0, 17.0, 0.0, 1.0, 7.0, 2.0,...</td>\n",
       "      <td>(0.0, 2.3583963217651585, 0.0, 1.6646415888996...</td>\n",
       "      <td>[0.24118939728349553, 0.11745402368601676, 0.9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"hep-ph9602267\"</td>\n",
       "      <td>[\"this, paper, explores, the, phenomenology, o...</td>\n",
       "      <td>(0.0, 3.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, ...</td>\n",
       "      <td>(0.0, 0.8843986206619344, 0.0, 0.4161603972249...</td>\n",
       "      <td>[0.24687892577787154, 0.08912597029620804, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"1307.2735\"</td>\n",
       "      <td>[\"the, classical, method, of, adding, two, int...</td>\n",
       "      <td>(0.0, 1.0, 5.0, 0.0, 0.0, 0.0, 3.0, 1.0, 0.0, ...</td>\n",
       "      <td>(0.0, 0.2947995402206448, 5.710487003039243, 0...</td>\n",
       "      <td>[0.11215675867134679, 0.10707027723770982, 0.1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id                                            content  \\\n",
       "0    \"hep-ph0205344\"  [\"the, standard, model, is, greatly, successfu...   \n",
       "1  \"astro-ph0612210\"  [\"the, study, of, the, formation, and, evoluti...   \n",
       "2        \"1401.4918\"  [\"the, dynamical, density, matrix, renormaliza...   \n",
       "3    \"hep-ph9602267\"  [\"this, paper, explores, the, phenomenology, o...   \n",
       "4        \"1307.2735\"  [\"the, classical, method, of, adding, two, int...   \n",
       "\n",
       "                                            features  \\\n",
       "0  (0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 1.0, 0.0, ...   \n",
       "1  (0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, ...   \n",
       "2  (0.0, 8.0, 0.0, 4.0, 17.0, 0.0, 1.0, 7.0, 2.0,...   \n",
       "3  (0.0, 3.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, ...   \n",
       "4  (0.0, 1.0, 5.0, 0.0, 0.0, 0.0, 3.0, 1.0, 0.0, ...   \n",
       "\n",
       "                                                 idf  \\\n",
       "0  (0.0, 0.2947995402206448, 1.1420974006078486, ...   \n",
       "1  (0.0, 0.8843986206619344, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2  (0.0, 2.3583963217651585, 0.0, 1.6646415888996...   \n",
       "3  (0.0, 0.8843986206619344, 0.0, 0.4161603972249...   \n",
       "4  (0.0, 0.2947995402206448, 5.710487003039243, 0...   \n",
       "\n",
       "                                           sim_score  \n",
       "0  [1.0, 0.12423407925986085, 0.24118939728349553...  \n",
       "1  [0.12423407925986085, 1.0, 0.11745402368601676...  \n",
       "2  [0.24118939728349553, 0.11745402368601676, 0.9...  \n",
       "3  [0.24687892577787154, 0.08912597029620804, 0.1...  \n",
       "4  [0.11215675867134679, 0.10707027723770982, 0.1...  "
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final = tf_idf.join(sim_df,[\"id\"])\n",
    "final.toPandas()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e5030792b3492f6b12d94f1f48beca3d8e59ec05fd59d0aaaa48e684281ed297"
  },
  "kernelspec": {
   "display_name": "Python 3.7.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
